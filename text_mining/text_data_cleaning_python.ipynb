{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.6\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1.Escaping HTML characters: \n",
    "\n",
    "Data obtained from web usually contains a lot of html entities like &lt; &gt; &amp; which gets embedded in the original data. It is thus necessary to get rid of these entities. One approach is to directly remove them by the use of specific regular expressions. Another approach is to use appropriate packages and modules (for example htmlparser of Python), which can convert these entities to standard html tags. For example: &lt; is converted to â€œ<â€ and &amp; is converted to â€œ&â€."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Escaping HTML Characters\n",
      "\n",
      "\n",
      "I luv my <3 iphone & youre awsm apple. DisplayIsAwesome, sooo happppppy  http://www.apple.com\n"
     ]
    }
   ],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "original_tweet = \"I luv my &lt;3 iphone &amp; youâ€™re awsm apple. DisplayIsAwesome, sooo happppppy ðŸ™‚ http://www.apple.com\"\n",
    "\n",
    "print('\\n\\nEscaping HTML Characters\\n\\n')\n",
    "\n",
    "html_parser = HTMLParser()\n",
    "\n",
    "original_tweet = original_tweet.decode('utf8').encode('ascii','ignore')\n",
    "\n",
    "tweet = html_parser.unescape(original_tweet)\n",
    "\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.Decoding data: \n",
    "This is the process of transforming information from complex symbols to simple and easier to understand characters. Text data may be subject to different forms of decoding like â€œLatinâ€, â€œUTF8â€ etc. Therefore, for better analysis, it is necessary to keep the complete data in standard encoding format. UTF-8 encoding is widely accepted and is recommended to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I luv my &lt;3 iphone &amp; youâ€™re awsm apple. DisplayIsAwesome, sooo happppppy ðŸ™‚ http://www.apple.com'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(original_tweet))\n",
    "original_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'original_tweet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-806bc6db766e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweet_02\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_tweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# output is like this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtweet_02\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"I luv my <3 iphone & you're awsm apple. DisplayIsAwesome, sooo happppppy ðŸ™‚ http://www.apple.com\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'original_tweet' is not defined"
     ]
    }
   ],
   "source": [
    "tweet_02 = original_tweet.decode('utf8').encode('ascii','ignore')\n",
    "\n",
    "# output is like this\n",
    "tweet_02=\"I luv my <3 iphone & you're awsm apple. DisplayIsAwesome, sooo happppppy ðŸ™‚ http://www.apple.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tweet_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Apostrophe Lookup: \n",
    "\n",
    "To avoid any word sense disambiguation in text, it is recommended to maintain proper structure in it and to abide by the rules of context free grammar. When apostrophes are used, chances of disambiguation increases.\n",
    "For example â€œitâ€™s is a contraction for it is or it hasâ€.\n",
    "\n",
    "All the apostrophes should be converted into standard lexicons. One can use a lookup table of all possible keys to get rid of disambiguates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"'s\": ' is', \"'re\": 'are'}\n",
      "I luv my <3 iphone & you're awsm apple. DisplayIsAwesome, sooo happppppy ðŸ™‚ http://www.apple.com\n"
     ]
    }
   ],
   "source": [
    "APPOSTOPHES = {\"'s\" : \" is\", \"'re\" : \"are\"} ## Need a huge dictionary\n",
    "\n",
    "print(APPOSTOPHES)\n",
    "\n",
    "words = tweet_02.split()\n",
    "tweet_03 = [APPOSTOPHES[word] if word in APPOSTOPHES else word for word in words]\n",
    "tweet_03 = \" \".join(tweet_03)\n",
    "\n",
    "print(tweet_03)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'luv',\n",
       " 'my',\n",
       " '<3',\n",
       " 'iphone',\n",
       " '&',\n",
       " \"you're\",\n",
       " 'awsm',\n",
       " 'apple.',\n",
       " 'DisplayIsAwesome,',\n",
       " 'sooo',\n",
       " 'happppppy',\n",
       " 'ðŸ™‚',\n",
       " 'http://www.apple.com']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4. Removal of Stop-words: \n",
    "When data analysis needs to be data driven at the word level, the commonly occurring words (stop-words) should be removed. One can either create a long list of stop-words or one can use predefined language specific libraries.\n",
    "### 5. Removal of Punctuations: \n",
    "All the punctuation marks according to the priorities should be dealt with. For example: â€œ.â€, â€œ,â€,â€?â€ are important punctuations that should be retained while others need to be removed.\n",
    "### 6. Removal of Expressions: \n",
    "Textual data (usually speech transcripts) may contain human expressions like [laughing], [Crying], [Audience paused]. These expressions are usually non relevant to content of the speech and hence need to be removed. Simple regular expression can be useful in this case.\n",
    "### 7. Split Attached Words: \n",
    "We humans in the social forums generate text data, which is completely informal in nature. Most of the tweets are accompanied with multiple attached words like RainyDay, PlayingInTheCold etc. These entities can be split into their normal forms using simple rules and regex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 8. Slangs lookup: \n",
    "Again, social media comprises of a majority of slang words. These words should be transformed into standard words to make free text. The words like luv will be converted to love, Helo to Hello. The similar approach of apostrophe look up can be used to convert slangs to standard words. A number of sources are available on the web, which provides lists of all possible slangs, this would be your holy grail and you could use them as lookup dictionaries for conversion purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 9. Standardizing words: \n",
    "\n",
    "Sometimes words are not in proper formats. For example: â€œI looooveee youâ€ should be â€œI love youâ€. Simple rules and regular expressions can help solve these cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 10. Removal of URLs: \n",
    "URLs and hyperlinks in text data like comments, reviews, and tweets should be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text = ['This is dirty TEXT: A phone number +001234561234, moNey 3.333, some date like 09.08.2016 and weird ÄŒÃ¡rÃ¡kterÅ¡.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is dirty TEXT: A phone number +001234561234, moNey 3.333, some date like 09.08.2016 and weird \\xc4\\x8c\\xc3\\xa1r\\xc3\\xa1kter\\xc5\\xa1.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_digit(word):\n",
    "    try:\n",
    "        int(word)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "cedilla2latin = [[u'Ã', u'A'], [u'Ã¡', u'a'], [u'ÄŒ', u'C'], [u'Ä', u'c'], [u'Å ', u'S'], [u'Å¡', u's']]\n",
    "tr = dict([(a[0], a[1]) for (a) in cedilla2latin])\n",
    "\n",
    "def transliterate(line):\n",
    "    new_line = \"\"\n",
    "    for letter in line:\n",
    "        if letter in tr:\n",
    "            new_line += tr[letter]\n",
    "        else:\n",
    "            new_line += letter\n",
    "    return new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is dirty text a phone number money some date like and weird carakters\n"
     ]
    }
   ],
   "source": [
    "for line in text:\n",
    "    # decode line to worrk with utf8 symbols\n",
    "    line = line.decode('utf8')\n",
    "    line = line.replace('+', ' ').replace('.', ' ').replace(',', ' ').replace(':', ' ')\n",
    "    # remove digits with regex\n",
    "    line = re.sub(\"(^|\\W)\\d+($|\\W)\", \" \", line)\n",
    "    # OR remove digits with casting to int\n",
    "    new_line = []\n",
    "    for word in line.split():\n",
    "        if not is_digit(word):\n",
    "            new_line.append(word)\n",
    "    line = \" \".join(new_line)\n",
    "    # transliterate to Latin characters\n",
    "    line = transliterate(line)\n",
    "    line = line.lower()\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
