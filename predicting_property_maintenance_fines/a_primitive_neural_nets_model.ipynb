{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background about Blight Violation in Detroit \n",
    "This information is obtained from the link: https://detroitmi.gov/Portals/0/docs/Brochures/DAH/DAH_Citizen_Guide.pdf\n",
    "\n",
    "### What is a Blight Violation? \n",
    "The City of Detroit has ordinances that address how property owners must maintain the exterior of their property. The City issues a blight violation when an owner fails to follow these ordinances. Examples of blight violations that come before the DAH are:\n",
    "* <b>Property Maintenance</b>: Failure to obtain certificate of compliance or rental registration, failure to maintain exterior of property, failure to comply with emergency order, rat harborage and failure to remove snow and ice.\n",
    "* <b>Zoning</b>: Violation of special land use grant, change of use of land without permit, change of use of building without a permit, failure to obtain certificate of maintenance of grant conditions.\n",
    "* <b>Solid Waste & Illegal Dumping</b>: Early or late placement or improper storage of Courville containers, improper set-out during eviction, improper storage of solid, medial or hazardous waste, improper bulk set-out and illegal dumping\n",
    " \n",
    "### Who issues Blight Violation Notices (BVNs)?\n",
    "Blight Violation Notices (BVNs) are written tickets issued by City inspectors, police officers, and other City officials who investigate complaints of blight. Blight violation notices are issued to property owners or those in control of property that is in violation of the City’s anti-blight ordinances. If a blight violation notice is issued, the person or entity in receipt is called a respondent.\n",
    "### What happens when a Blight Violation Notice (BVN) is issued?\n",
    "The written blight violation notice (BVN) received by a respondent will provide a description of the alleged violation and give the hearing date and time. Once a BVN is issued, the following options are available to the respondent who received the BVN:\n",
    "* Admit responsibility and pay the fine and fees before the DAH hearing date; fine is reduced 10% for early payment.\n",
    "* Attend the hearing and contest the blight violation, with or without an attorney.\n",
    "* If a property owner is found responsible at the hearing, the fine and fees imposed must be paid by the hearing date or a 10% penalty is imposed for late payment.\n",
    "\n",
    "### What is the DAH Hearing Process?\n",
    "A respondent who receives a blight violation notice has the right to attend a hearing at the DAH. At the hearing, the respondent may present a defense to the blight violation. DAH hearings are presided over by Administrative Hearing Officers who are licensed Michigan attorneys and independent contractors. At the conclusion of the hearing, the Administrative Hearing Officer will make finding of facts and issue a written Decision and Order and Judgment. A Decision and Order and Judgment issued by the DAH is a state civil judgment and is treated the same as any other state court judgment for enforcement purposes\n",
    "\n",
    "### What if payment is not made?\n",
    "If an individual ignores a blight violation notice and doesn’t appear at the hearing, a Decision and Order and Judgment by Default will be issued finding the respondent responsible for the blight violation. If a respondent fails to pay the amount of the Decision and Order and Judgment, collection actions will be commenced, which may include the garnishment of wages, attachment of bank accounts and assets, and imposition of judgment liens upon real property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "# Part A: Taking a look of the datasets\n",
    "\n",
    "(Detailed examination of the datasets is provided in the script \"introduction_and_data_exploration.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingjinghuang/miniconda3/envs/pythonj3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (11,12,31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "#from sklearn.grid_search import RandomizedSearchCV\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "print(sklearn.__version__)\n",
    "\n",
    "traindata = pd.read_csv('train.csv',encoding = \"ISO-8859-1\")\n",
    "testdata = pd.read_csv('test.csv',encoding = \"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250306, 34) (61001, 27)\n",
      "features of traindata Index(['ticket_id', 'agency_name', 'inspector_name', 'violator_name',\n",
      "       'violation_street_number', 'violation_street_name',\n",
      "       'violation_zip_code', 'mailing_address_str_number',\n",
      "       'mailing_address_str_name', 'city', 'state', 'zip_code',\n",
      "       'non_us_str_code', 'country', 'ticket_issued_date', 'hearing_date',\n",
      "       'violation_code', 'violation_description', 'disposition', 'fine_amount',\n",
      "       'admin_fee', 'state_fee', 'late_fee', 'discount_amount',\n",
      "       'clean_up_cost', 'judgment_amount', 'payment_amount', 'balance_due',\n",
      "       'payment_date', 'payment_status', 'collection_status',\n",
      "       'grafitti_status', 'compliance_detail', 'compliance'],\n",
      "      dtype='object')\n",
      "features of testdata Index(['ticket_id', 'agency_name', 'inspector_name', 'violator_name',\n",
      "       'violation_street_number', 'violation_street_name',\n",
      "       'violation_zip_code', 'mailing_address_str_number',\n",
      "       'mailing_address_str_name', 'city', 'state', 'zip_code',\n",
      "       'non_us_str_code', 'country', 'ticket_issued_date', 'hearing_date',\n",
      "       'violation_code', 'violation_description', 'disposition', 'fine_amount',\n",
      "       'admin_fee', 'state_fee', 'late_fee', 'discount_amount',\n",
      "       'clean_up_cost', 'judgment_amount', 'grafitti_status'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# check datasets shapes\n",
    "print(traindata.shape, testdata.shape)\n",
    "\n",
    "# check features\n",
    "print('features of traindata', traindata.columns)\n",
    "print('features of testdata', testdata.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on analysis of features, these features may be used:\n",
    "( note: both date and string variables will be tested)\n",
    "* inspector_name\n",
    "* violation_street_name\n",
    "* mailing_address_str_name\n",
    "* *ticket_issued_date* (how can we use this to predict future observations? different months may have different propensities for blight?)\n",
    "* *hearing_date* (how can we use this to predict future observations? This seems very relevant !!!)\n",
    "* violation_code\n",
    "* violation_description\n",
    "* disposition\n",
    "* fine_amount (0.0 or othersize)\n",
    "* late_fee\n",
    "* discount_amount\n",
    "* judgment_amount\n",
    "\n",
    "### I finally decided to start with these features for constructing a RandomForest model;\n",
    "* disposition\n",
    "* timegap - a new feature that is constructed based on ticket_issued_date and hearing date\n",
    "* fine_amount \n",
    "* discount_amount\n",
    "* judgment_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <br>\n",
    " <br>\n",
    "  <br>\n",
    "Next, we're going to... \n",
    " \n",
    " <br>\n",
    " <br>\n",
    "# Build a MLPRegressor\n",
    "(note that I have optimized parameters for this model and details are in the script \"introduction_and_data_exploration.ipynb\")\n",
    " <br>\n",
    " <br>\n",
    " <br>\n",
    " <br>\n",
    " <br>\n",
    " <br>\n",
    " \n",
    "### 1. Loading and processing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingjinghuang/miniconda3/envs/pythonj3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (11,12,31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "#from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)\n",
    "\n",
    "# read the two datasets\n",
    "traindata = pd.read_csv('train.csv',encoding = \"ISO-8859-1\")\n",
    "testdata = pd.read_csv('test.csv',encoding = \"ISO-8859-1\")\n",
    "\n",
    "# add one more feature\n",
    "columns_to_keep = ['disposition','fine_amount','late_fee', 'discount_amount',\n",
    "                   'judgment_amount','hearing_date', 'ticket_issued_date', 'compliance']\n",
    "columns_to_keep_test = ['disposition','fine_amount','late_fee', 'discount_amount',\n",
    "                        'judgment_amount','hearing_date', 'ticket_issued_date']\n",
    "\n",
    "traindata = traindata[columns_to_keep]\n",
    "testdata = testdata[columns_to_keep_test]\n",
    "\n",
    "# reduce memory usage by casting\n",
    "for i in range(len(traindata.columns)):\n",
    "    if len(traindata[traindata.columns[i]].unique()) < 250:\n",
    "        traindata[traindata.columns[i]] = traindata[traindata.columns[i]].astype('category')\n",
    "\n",
    "# Double check and drop any of the columns and rows that contains NAN\n",
    "traindata = traindata.dropna(axis=1,how='all') # drop columns that contain only Nans\n",
    "traindata = traindata.dropna(axis=0,how='any') # drop rows that contain at least one Nan\n",
    "traindata = traindata[traindata['compliance'].notnull()]\n",
    "\n",
    "\n",
    "# to make sure the disposition variable is same in both training and testing sets \n",
    "traindata['disposition'] = traindata.disposition.astype(str)\n",
    "testdata['disposition'] = testdata.disposition.astype(str)\n",
    "\n",
    "\n",
    "# there are few instances in the testdata set that contain strange values of the 'diposition' variable;\n",
    "# these values are not present in the traindata set, and therefore, I replaced these values with the values \n",
    "# from the traindata set\n",
    "testdata['disposition'].replace(['Responsible (Fine Waived) by Admis'], 'Responsible by Admission',inplace=True)\n",
    "testdata['disposition'].replace(['Responsible - Compl/Adj by Default'], 'Responsible by Default',inplace=True)\n",
    "testdata['disposition'].replace(['Responsible - Compl/Adj by Determi'], 'Responsible by Determination',inplace=True)\n",
    "testdata['disposition'].replace(['Responsible by Dismissal'], 'Responsible (Fine Waived) by Deter',inplace=True)\n",
    "\n",
    "\n",
    "# process the date time variables\n",
    "traindata['hearing_date'] = pd.to_datetime(traindata['hearing_date'])\n",
    "traindata['ticket_issued_date'] = pd.to_datetime(traindata['ticket_issued_date'])\n",
    "testdata['hearing_date'] = pd.to_datetime(testdata['hearing_date'])\n",
    "testdata['ticket_issued_date'] = pd.to_datetime(testdata['ticket_issued_date'])\n",
    "\n",
    "\n",
    "# compute a new variable date time gap\n",
    "traindata['time_gap'] = traindata['hearing_date'].subtract(traindata['ticket_issued_date'])\n",
    "traindata['time_gap'] = traindata['time_gap'].dt.days\n",
    "traindata.drop(['hearing_date','ticket_issued_date'],axis = 1,inplace = True)\n",
    "testdata['time_gap'] = testdata['hearing_date'].subtract(testdata['ticket_issued_date'])\n",
    "testdata['time_gap'] = testdata['time_gap'].dt.days\n",
    "testdata.drop(['hearing_date','ticket_issued_date'],axis = 1,inplace = True)\n",
    "\n",
    "# process and transform string_features to two-digit variables\n",
    "string_features = ['disposition']\n",
    "traindata =  pd.get_dummies(traindata,columns = string_features,drop_first = False)\n",
    "testdata =  pd.get_dummies(testdata,columns = string_features,drop_first = False)\n",
    "\n",
    "y = traindata['compliance']\n",
    "X = traindata.drop('compliance',axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "#rescale the training and test sets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#rescale the final testdata\n",
    "testdata_full = pd.read_csv('test.csv',encoding = \"ISO-8859-1\")\n",
    "testdata = testdata.fillna(value=0)\n",
    "\n",
    "testdata = scaler.transform(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fine_amount</th>\n",
       "      <th>late_fee</th>\n",
       "      <th>discount_amount</th>\n",
       "      <th>judgment_amount</th>\n",
       "      <th>compliance</th>\n",
       "      <th>time_gap</th>\n",
       "      <th>disposition_Responsible (Fine Waived) by Deter</th>\n",
       "      <th>disposition_Responsible by Admission</th>\n",
       "      <th>disposition_Responsible by Default</th>\n",
       "      <th>disposition_Responsible by Determination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>750.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>378</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>250.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>750.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fine_amount late_fee discount_amount judgment_amount compliance  time_gap  \\\n",
       "0       250.0     25.0             0.0           305.0        0.0       369   \n",
       "1       750.0     75.0             0.0           855.0        1.0       378   \n",
       "5       250.0     25.0             0.0           305.0        0.0       323   \n",
       "6       750.0     75.0             0.0           855.0        0.0       253   \n",
       "7       100.0     10.0             0.0           140.0        0.0       251   \n",
       "\n",
       "   disposition_Responsible (Fine Waived) by Deter  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "5                                               0   \n",
       "6                                               0   \n",
       "7                                               0   \n",
       "\n",
       "   disposition_Responsible by Admission  disposition_Responsible by Default  \\\n",
       "0                                     0                                   1   \n",
       "1                                     0                                   0   \n",
       "5                                     0                                   1   \n",
       "6                                     0                                   1   \n",
       "7                                     0                                   1   \n",
       "\n",
       "   disposition_Responsible by Determination  \n",
       "0                                         0  \n",
       "1                                         1  \n",
       "5                                         0  \n",
       "6                                         0  \n",
       "7                                         0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(119739, 9)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Other quick and simple models as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9288720749611665 0.9282439305489439 0.5\n",
      "0.9226837701057273 0.9204269285696389 0.6279130794774737\n",
      "0.9226837701057273 0.9204269285696389\n"
     ]
    }
   ],
   "source": [
    "# some other models as baselines\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy = 'most_frequent').fit(X_train,y_train)\n",
    "ypred = dummy_clf.predict(X_test)\n",
    "\n",
    "print(dummy_clf.score(X_test,y_test),dummy_clf.score(X_train,y_train),roc_auc_score(y_test,ypred))\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nbclf = GaussianNB().fit(X_train, y_train)\n",
    "y_pred = nbclf.predict(X_test)\n",
    "y_train_pred = nbclf.predict(X_train)\n",
    "\n",
    "print(nbclf.score(X_test, y_test),(nbclf.score(X_train, y_train)), roc_auc_score(y_test,y_pred))\n",
    "#print(accuracy_score(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred),accuracy_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9226837701057273 0.9204269285696389\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred),accuracy_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run GridSearchCV to attain paramters for neural network\n",
    "This was run exclusively by supercomputers, and the section here is shown just for double check!\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "#### Here is the piece of the codes that was run on a HPC cluster: <br>\n",
    "----------------------------------------------------------------\n",
    "\\#Number of hidden layers <br>\n",
    "aa=[a for a in range(0,110,10)] <br>\n",
    "hidden_layer_sizes=[(a,a) for a in aa[1:]] <br>\n",
    "\n",
    "\\#Activation function for the hidden layer <br>\n",
    "activation= ['tanh', 'relu']\n",
    "\n",
    "\\#The solver for weight optimization <br>\n",
    "solver=['sgd', 'adam','lbfgs'], <br>\n",
    "\n",
    "\\#L2 penalty (regularization term) parameter <br>\n",
    "alpha = [0.0001, 0.0005, 0.001] <br>\n",
    "\n",
    "\\#Learning rate schedule for weight updates <br>\n",
    "learning_rate = ['constant','adaptive'] <br>\n",
    "\n",
    "\\#Create the random grid <br>\n",
    "param_grid =  {'hidden_layer_sizes': hidden_layer_sizes, 'activation': activation, 'solver': solver, \n",
    "               'alpha': alpha, 'learning_rate': learning_rate} \n",
    "\n",
    "reg_NN = MLPRegressor() <br> \n",
    "\n",
    "grid_reg_NN = RandomizedSearchCV(estimator = reg_NN, param_distributions = param_grid, \n",
    "                               n_iter = 5000, cv = 3, verbose=2, random_state=42,  \n",
    "                                        n_jobs = -1, scoring='roc_auc')\n",
    "\n",
    "grid_reg_NN.fit(X_train, y_train) <br>\n",
    "\n",
    "print('Grid best parameter (max. accuracy): ', grid_reg_NN.best_params_) <br>\n",
    "print('Grid best score (roc_auc): ', grid_reg_NN.best_score_) <br>\n",
    "\n",
    "-----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter (max. accuracy):  {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "Grid best score (roc_auc):  0.7941070128293706\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_sizes = [(10,)] \n",
    "activation = ['relu']\n",
    "solver = ['adam']\n",
    "alpha = [0.0001] \n",
    "learning_rate = ['constant'] \n",
    "\n",
    "param_grid =  {'hidden_layer_sizes': hidden_layer_sizes, 'activation': activation, 'solver': solver, \n",
    "               'alpha': alpha,'learning_rate': learning_rate} \n",
    "\n",
    "reg_NN = MLPClassifier() \n",
    "\n",
    "grid_reg_NN = GridSearchCV(reg_NN, param_grid = param_grid, n_jobs=-1, scoring='roc_auc')\n",
    "grid_reg_NN.fit(X_train, y_train) \n",
    "\n",
    "print('Grid best parameter (max. accuracy): ', grid_reg_NN.best_params_) \n",
    "print('Grid best score (roc_auc): ', grid_reg_NN.best_score_) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best score (roc_auc):  0.7937066885010167\n"
     ]
    }
   ],
   "source": [
    "# Create the random grid\n",
    "param_grid =  {'hidden_layer_sizes': [10],\n",
    "               'activation': ['relu'],\n",
    "               'solver': ['adam'],\n",
    "               'learning_rate': ['constant'],\n",
    "               'alpha':[0.0001]}\n",
    "\n",
    "\n",
    "reg_NN = MLPClassifier() \n",
    "\n",
    "grid_reg_NN = GridSearchCV(reg_NN, param_grid = param_grid, n_jobs=-1, scoring='roc_auc')\n",
    "\n",
    "grid_reg_NN.fit(X_train, y_train)\n",
    "print('Grid best score (roc_auc): ', grid_reg_NN.best_score_) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseSearchCV.score of GridSearchCV(estimator=MLPClassifier(), n_jobs=-1,\n",
       "             param_grid={'activation': ['relu'], 'alpha': [0.0001],\n",
       "                         'hidden_layer_sizes': [10],\n",
       "                         'learning_rate': ['constant'], 'solver': ['adam']},\n",
       "             scoring='roc_auc')>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_reg_NN.score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build Neural Network using the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.8000819277656926\n",
    "reg_NN = MLPClassifier(hidden_layer_sizes=10,\n",
    "                       activation='relu', \n",
    "                       solver='adam',\n",
    "                       learning_rate='constant',\n",
    "                       alpha=0.0001)\n",
    "\n",
    "\n",
    "reg_NN.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7962854790849483 0.7934998481083131\n",
      "0.9424763240968081 0.9417148965666993\n"
     ]
    }
   ],
   "source": [
    "#ypred_train = reg_NN.predict(X_train)\n",
    "#ypred_test = reg_NN.predict(X_test)\n",
    "ypred_train = reg_NN.predict_proba(X_train)[:,1]\n",
    "ypred_test = reg_NN.predict_proba(X_test)[:,1] # 1 means positive class\n",
    "\n",
    "print(roc_auc_score(y_train,ypred_train), roc_auc_score(y_test,ypred_test))\n",
    "print(reg_NN.score(X_test,y_test),reg_NN.score(X_train,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29178     0.0\n",
       "204411    0.0\n",
       "9770      0.0\n",
       "49487     0.0\n",
       "73038     0.0\n",
       "         ... \n",
       "14705     0.0\n",
       "216340    0.0\n",
       "203210    0.0\n",
       "15817     0.0\n",
       "246743    0.0\n",
       "Name: compliance, Length: 39914, dtype: category\n",
       "Categories (2, float64): [0.0, 1.0]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Make predictions for the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of MLPClassifier(hidden_layer_sizes=10)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_NN.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "test_pred = reg_NN.predict_proba(testdata)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.95309683 0.04690317]\n",
      " [0.98533614 0.01466386]\n",
      " [0.93153769 0.06846231]\n",
      " ...\n",
      " [0.92908925 0.07091075]\n",
      " [0.92908925 0.07091075]\n",
      " [0.85642018 0.14357982]]\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(reg_NN.predict_proba(testdata))\n",
    "print(reg_NN.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd.DataFrame(test_pred, index=testdata_full['ticket_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticket_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284932</th>\n",
       "      <td>0.046903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285362</th>\n",
       "      <td>0.014664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285361</th>\n",
       "      <td>0.068462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285338</th>\n",
       "      <td>0.043956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285346</th>\n",
       "      <td>0.066560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "ticket_id          \n",
       "284932     0.046903\n",
       "285362     0.014664\n",
       "285361     0.068462\n",
       "285338     0.043956\n",
       "285346     0.066560"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
